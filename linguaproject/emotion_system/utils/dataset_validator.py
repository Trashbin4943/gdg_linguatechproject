"""
ë°ì´í„°ì…‹ ê²€ì¦ ë° ë¡œë“œ ìœ í‹¸ë¦¬í‹°

ë°ì´í„°ì…‹ì˜ í˜•ì‹ê³¼ í’ˆì§ˆì„ ê²€ì¦í•˜ê³ , í•„ìš”í•œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ë„êµ¬
"""

import pandas as pd
import json
from typing import List, Dict, Tuple, Optional
import os
from pathlib import Path

# ë¼ë²¨ ë§¤í•‘ (classification_criteria.pyì™€ ë™ì¼)
LABEL_MAPPING = {
    "ì •ìƒ": 0,
    "ìš•ì„¤_ì €ì£¼": 1,
    "ëª¨ìš•_ì¡°ë¡±": 2,
    "í­ë ¥_ìœ„í˜‘_ë²”ì£„ì¡°ì¥": 3,
    "ì™¸ì„¤_ì„±í¬ë¡±": 4,
    "í˜ì˜¤í‘œí˜„": 5,
    "ë°˜ë³µì„±": 6,
    "ë¬´ë¦¬í•œ_ìš”êµ¬": 7,
    "ë¶€ë‹¹ì„±": 8,
    "í—ˆìœ„_ë¯¼ì›": 9,
    "ì¥ë‚œì „í™”": 10,
    "ê³µí¬ì‹¬_ë¶ˆì•ˆê°_ìœ ë°œ": 11
}

VALID_LABELS = set(LABEL_MAPPING.keys())
VALID_SEVERITIES = {"NORMAL", "LOW", "MEDIUM", "HIGH", "CRITICAL"}


class DatasetValidator:
    """ë°ì´í„°ì…‹ ê²€ì¦ í´ë˜ìŠ¤"""
    
    def __init__(self, required_columns: List[str] = None):
        """
        Args:
            required_columns: í•„ìˆ˜ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸ (ê¸°ë³¸: ['text', 'label'])
        """
        self.required_columns = required_columns or ['text', 'label']
        self.errors = []
        self.warnings = []
    
    def validate(self, df: pd.DataFrame) -> Tuple[bool, List[str], List[str]]:
        """
        ë°ì´í„°ì…‹ ê²€ì¦
        
        Returns:
            (is_valid, errors, warnings)
        """
        self.errors = []
        self.warnings = []
        
        # 1. í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        self._check_required_columns(df)
        
        # 2. ë¹ˆ ê°’ í™•ì¸
        self._check_empty_values(df)
        
        # 3. ë¼ë²¨ ìœ íš¨ì„± í™•ì¸
        self._check_label_validity(df)
        
        # 4. ë°ì´í„° ê·œëª¨ í™•ì¸
        self._check_data_size(df)
        
        # 5. ë¼ë²¨ ë¶„í¬ í™•ì¸
        self._check_label_distribution(df)
        
        # 6. ì„¸ì…˜ ì •ë³´ í™•ì¸ (ìˆëŠ” ê²½ìš°)
        if 'session_id' in df.columns:
            self._check_session_info(df)
        
        # 7. í…ìŠ¤íŠ¸ í’ˆì§ˆ í™•ì¸
        self._check_text_quality(df)
        
        is_valid = len(self.errors) == 0
        return is_valid, self.errors, self.warnings
    
    def _check_required_columns(self, df: pd.DataFrame):
        """í•„ìˆ˜ ì»¬ëŸ¼ ì¡´ì¬ í™•ì¸"""
        missing = [col for col in self.required_columns if col not in df.columns]
        if missing:
            self.errors.append(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {', '.join(missing)}")
    
    def _check_empty_values(self, df: pd.DataFrame):
        """ë¹ˆ ê°’ í™•ì¸"""
        if 'text' in df.columns:
            null_count = df['text'].isna().sum()
            if null_count > 0:
                self.errors.append(f"text ì»¬ëŸ¼ì— NULL ê°’ {null_count}ê°œ ì¡´ì¬")
            
            empty_count = (df['text'].astype(str).str.strip() == '').sum()
            if empty_count > 0:
                self.errors.append(f"text ì»¬ëŸ¼ì— ë¹ˆ ë¬¸ìì—´ {empty_count}ê°œ ì¡´ì¬")
        
        if 'label' in df.columns:
            null_count = df['label'].isna().sum()
            if null_count > 0:
                self.errors.append(f"label ì»¬ëŸ¼ì— NULL ê°’ {null_count}ê°œ ì¡´ì¬")
    
    def _check_label_validity(self, df: pd.DataFrame):
        """ë¼ë²¨ ìœ íš¨ì„± í™•ì¸"""
        if 'label' not in df.columns:
            return
        
        invalid_labels = []
        for idx, label_str in df['label'].items():
            if pd.isna(label_str):
                continue
            
            labels = str(label_str).split('|')
            for label in labels:
                label = label.strip()
                if label and label not in VALID_LABELS:
                    invalid_labels.append((idx, label))
        
        if invalid_labels:
            examples = invalid_labels[:5]  # ì²˜ìŒ 5ê°œë§Œ í‘œì‹œ
            self.errors.append(
                f"ì˜ëª»ëœ ë¼ë²¨ {len(invalid_labels)}ê°œ ë°œê²¬. ì˜ˆì‹œ: {examples}"
            )
    
    def _check_data_size(self, df: pd.DataFrame):
        """ë°ì´í„° ê·œëª¨ í™•ì¸"""
        total = len(df)
        
        if total < 500:
            self.warnings.append(
                f"ë°ì´í„°ê°€ ë„ˆë¬´ ì ìŒ: {total}ê°œ (ìµœì†Œ 500ê°œ ê¶Œì¥)"
            )
        elif total < 1000:
            self.warnings.append(
                f"ë°ì´í„° ê·œëª¨ê°€ ì‘ìŒ: {total}ê°œ (1,000ê°œ ì´ìƒ ê¶Œì¥)"
            )
    
    def _check_label_distribution(self, df: pd.DataFrame):
        """ë¼ë²¨ ë¶„í¬ í™•ì¸"""
        if 'label' not in df.columns:
            return
        
        label_counts = {}
        for label_str in df['label']:
            if pd.isna(label_str):
                continue
            labels = str(label_str).split('|')
            for label in labels:
                label = label.strip()
                if label:
                    label_counts[label] = label_counts.get(label, 0) + 1
        
        # ê° ë¼ë²¨ë³„ ìµœì†Œ ê°œìˆ˜ í™•ì¸
        for label, count in label_counts.items():
            if count < 20:
                self.warnings.append(
                    f"ë¼ë²¨ '{label}' ìƒ˜í”Œ ë¶€ì¡±: {count}ê°œ (ìµœì†Œ 20ê°œ ê¶Œì¥)"
                )
        
        # ì •ìƒ ìƒ˜í”Œ ë¹„ìœ¨ í™•ì¸
        normal_count = label_counts.get('ì •ìƒ', 0)
        total = len(df)
        if total > 0:
            normal_ratio = normal_count / total
            if normal_ratio < 0.3:
                self.warnings.append(
                    f"ì •ìƒ ìƒ˜í”Œ ë¹„ìœ¨ì´ ë‚®ìŒ: {normal_ratio:.1%} (30% ì´ìƒ ê¶Œì¥)"
                )
            elif normal_ratio > 0.8:
                self.warnings.append(
                    f"ì •ìƒ ìƒ˜í”Œ ë¹„ìœ¨ì´ ë„ˆë¬´ ë†’ìŒ: {normal_ratio:.1%} (í´ë˜ìŠ¤ ë¶ˆê· í˜• ê°€ëŠ¥)"
                )
    
    def _check_session_info(self, df: pd.DataFrame):
        """ì„¸ì…˜ ì •ë³´ í™•ì¸"""
        if 'session_id' not in df.columns:
            return
        
        # ì„¸ì…˜ë³„ í„´ ìˆ˜ í™•ì¸
        if 'turn_id' in df.columns:
            session_turns = df.groupby('session_id')['turn_id'].count()
            single_turn_sessions = (session_turns == 1).sum()
            if single_turn_sessions > 0:
                self.warnings.append(
                    f"í„´ì´ 1ê°œì¸ ì„¸ì…˜ {single_turn_sessions}ê°œ (ë°˜ë³µì„± ê°ì§€ ì–´ë ¤ì›€)"
                )
    
    def _check_text_quality(self, df: pd.DataFrame):
        """í…ìŠ¤íŠ¸ í’ˆì§ˆ í™•ì¸"""
        if 'text' not in df.columns:
            return
        
        # í…ìŠ¤íŠ¸ ê¸¸ì´ í™•ì¸
        text_lengths = df['text'].astype(str).str.len()
        too_short = (text_lengths < 3).sum()
        too_long = (text_lengths > 1000).sum()
        
        if too_short > 0:
            self.warnings.append(f"ë„ˆë¬´ ì§§ì€ í…ìŠ¤íŠ¸ {too_short}ê°œ (3ì ë¯¸ë§Œ)")
        if too_long > 0:
            self.warnings.append(f"ë„ˆë¬´ ê¸´ í…ìŠ¤íŠ¸ {too_long}ê°œ (1000ì ì´ˆê³¼)")
        
        # ê°œì¸ì •ë³´ íŒ¨í„´ í™•ì¸ (ê°„ë‹¨í•œ ì²´í¬)
        phone_pattern = r'\d{2,3}-\d{3,4}-\d{4}'
        email_pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}'
        
        phone_count = df['text'].astype(str).str.contains(phone_pattern, regex=True).sum()
        email_count = df['text'].astype(str).str.contains(email_pattern, regex=True).sum()
        
        if phone_count > 0:
            self.warnings.append(
                f"ì „í™”ë²ˆí˜¸ íŒ¨í„´ ë°œê²¬ {phone_count}ê°œ (ê°œì¸ì •ë³´ ë§ˆìŠ¤í‚¹ í•„ìš”)"
            )
        if email_count > 0:
            self.warnings.append(
                f"ì´ë©”ì¼ íŒ¨í„´ ë°œê²¬ {email_count}ê°œ (ê°œì¸ì •ë³´ ë§ˆìŠ¤í‚¹ í•„ìš”)"
            )


def load_dataset(file_path: str, format: Optional[str] = None) -> pd.DataFrame:
    """
    ë°ì´í„°ì…‹ ë¡œë“œ (CSV, JSON, Excel ì§€ì›)
    
    Args:
        file_path: íŒŒì¼ ê²½ë¡œ
        format: íŒŒì¼ í˜•ì‹ ('csv', 'json', 'excel', None=ìë™ ê°ì§€)
    
    Returns:
        DataFrame
    """
    path = Path(file_path)
    
    # í˜•ì‹ ìë™ ê°ì§€
    if format is None:
        if path.suffix.lower() == '.csv':
            format = 'csv'
        elif path.suffix.lower() in ['.json', '.jsonl']:
            format = 'json'
        elif path.suffix.lower() in ['.xlsx', '.xls']:
            format = 'excel'
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {path.suffix}")
    
    # íŒŒì¼ ë¡œë“œ
    if format == 'csv':
        # UTF-8 ë˜ëŠ” UTF-8-sig ì‹œë„
        try:
            df = pd.read_csv(file_path, encoding='utf-8')
        except UnicodeDecodeError:
            df = pd.read_csv(file_path, encoding='utf-8-sig')
    
    elif format == 'json':
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # JSON í˜•ì‹ì— ë”°ë¼ ë³€í™˜
        if isinstance(data, list):
            df = pd.DataFrame(data)
        elif isinstance(data, dict) and 'sessions' in data:
            # ì„¸ì…˜ ê¸°ë°˜ JSON í˜•ì‹
            rows = []
            for session in data['sessions']:
                session_id = session.get('session_id', '')
                for turn in session.get('turns', []):
                    row = {
                        'text': turn.get('text', ''),
                        'label': '|'.join(turn.get('labels', [])),
                        'session_id': session_id,
                        'turn_id': turn.get('turn_id', ''),
                        'speaker': turn.get('speaker', ''),
                        'severity': '|'.join(turn.get('severities', [])) if isinstance(turn.get('severities'), list) else turn.get('severity', '')
                    }
                    rows.append(row)
            df = pd.DataFrame(rows)
        else:
            df = pd.json_normalize(data)
    
    elif format == 'excel':
        df = pd.read_excel(file_path)
    
    else:
        raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹: {format}")
    
    return df


def validate_dataset(file_path: str, format: Optional[str] = None, 
                    required_columns: List[str] = None) -> Tuple[bool, List[str], List[str]]:
    """
    ë°ì´í„°ì…‹ íŒŒì¼ ê²€ì¦
    
    Args:
        file_path: íŒŒì¼ ê²½ë¡œ
        format: íŒŒì¼ í˜•ì‹ (None=ìë™ ê°ì§€)
        required_columns: í•„ìˆ˜ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸
    
    Returns:
        (is_valid, errors, warnings)
    """
    # ë°ì´í„° ë¡œë“œ
    try:
        df = load_dataset(file_path, format)
    except Exception as e:
        return False, [f"íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {str(e)}"], []
    
    # ê²€ì¦
    validator = DatasetValidator(required_columns)
    return validator.validate(df)


def print_validation_report(file_path: str, format: Optional[str] = None):
    """ê²€ì¦ ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥"""
    print("=" * 80)
    print(f"ë°ì´í„°ì…‹ ê²€ì¦: {file_path}")
    print("=" * 80)
    
    is_valid, errors, warnings = validate_dataset(file_path, format)
    
    print(f"\nğŸ“Š ê²€ì¦ ê²°ê³¼: {'âœ… í†µê³¼' if is_valid else 'âŒ ì‹¤íŒ¨'}")
    print(f"   - ì „ì²´ ë°ì´í„°: {len(load_dataset(file_path, format))}ê°œ")
    
    if errors:
        print(f"\nâŒ ì˜¤ë¥˜ ({len(errors)}ê°œ):")
        for i, error in enumerate(errors, 1):
            print(f"   {i}. {error}")
    
    if warnings:
        print(f"\nâš ï¸  ê²½ê³  ({len(warnings)}ê°œ):")
        for i, warning in enumerate(warnings, 1):
            print(f"   {i}. {warning}")
    
    if not errors and not warnings:
        print("\nâœ… ëª¨ë“  ê²€ì¦ í†µê³¼!")
    
    print("=" * 80)
    
    return is_valid


# ì‚¬ìš© ì˜ˆì œ
if __name__ == "__main__":
    # ì˜ˆì œ: ë°ì´í„°ì…‹ ê²€ì¦
    # print_validation_report('data/train.csv')
    
    # ì˜ˆì œ: ë°ì´í„°ì…‹ ë¡œë“œ
    # df = load_dataset('data/train.csv')
    # print(df.head())
    
    print("ë°ì´í„°ì…‹ ê²€ì¦ ë„êµ¬ ì¤€ë¹„ ì™„ë£Œ!")
    print("ì‚¬ìš©ë²•: print_validation_report('your_dataset.csv')")


